 grid computing is the collection of computer resources from multiple locations to reach a common goal  the grid can be thought of as a distributed system with non interactive workloads that involve a large number of files  grid computing is distinguished from conventional high performance computing systems such as cluster computing in that grid computers have each node set to perform a different task application   grid computers also tend to be more heterogeneous and geographically dispersed  thus not physically coupled  than cluster computers   although a single grid can be dedicated to a particular application  commonly a grid is used for a variety of purposes  grids are often constructed with general purpose grid middleware software libraries     grid size varies a considerable amount  grids are a form of distributed computing whereby a  super virtual computer  is composed of many networked loosely coupled computers acting together to perform large tasks  for certain applications   distributed  or  grid  computing  can be seen as a special type of parallel computing that relies on complete computers  with onboard cpus  storage  power supplies  network interfaces  etc   connected to a network  private or public  by a conventional network interface  such as ethernet  this is in contrast to the traditional notion of a supercomputer  which has many processors connected by a local high speed computer bus             grid computing combines computers from multiple administrative domains to reach a common goal   to solve a single task  and may then disappear just as quickly     one of the main strategies of grid computing is to use middleware to divide and apportion pieces of a program among several computers  sometimes up to many thousands  grid computing involves computation in a distributed fashion  which may also involve the aggregation of large scale clusters     the size of a grid may vary from small confined to a network of computer workstations within a corporation  for example to large  public collaborations across many companies and networks   the notion of a confined grid may also be known as an intra nodes cooperation whilst the notion of a larger  wider grid may thus refer to an inter nodes cooperation       grids are a form of distributed computing whereby a  super virtual computer  is composed of many networked loosely coupled computers acting together to perform very large tasks  this technology has been applied to computationally intensive scientific  mathematical  and academic problems through volunteer computing  and it is used in commercial enterprises for such diverse applications as drug discovery  economic forecasting  seismic analysis  and back office data processing in support for e commerce and web services     coordinating applications on grids can be a complex task  especially when coordinating the flow of information across distributed computing resources  grid workflow systems have been developed as a specialized form of a workflow management system designed specifically to compose and execute a series of computational or data manipulation steps  or a workflow  in the grid context      distributed  or  grid  computing in general is a special type of parallel computing that relies on complete computers  with onboard cpus  storage  power supplies  network interfaces  etc   connected to a network  private  public or the internet  by a conventional network interface producing commodity hardware  compared to the lower efficiency of designing and constructing a small number of custom supercomputers  the primary performance disadvantage is that the various processors and local storage areas do not have high speed connections  this arrangement is thus well suited to applications in which multiple parallel computations can take place independently  without the need to communicate intermediate results between processors   the high end scalability of geographically dispersed grids is generally favorable  due to the low need for connectivity between nodes relative to the capacity of the public internet citation needed    there are also some differences in programming and deployment  it can be costly and difficult to write programs that can run in the environment of a supercomputer  which may have a custom operating system  or require the program to address concurrency issues  if a problem can be adequately parallelized  a  thin  layer of  grid  infrastructure can allow conventional  standalone programs  given a different part of the same problem  to run on multiple machines  this makes it possible to write and debug on a single conventional machine  and eliminates complications due to multiple instances of the same program running in the same shared memory and storage space at the same time     one feature of distributed grids is that they can be formed from computing resources belonging to multiple individuals or organizations  known as multiple administrative domains   this can facilitate commercial transactions  as in utility computing  or make it easier to assemble volunteer computing networks     one disadvantage of this feature is that the computers which are actually performing the calculations might not be entirely trustworthy  the designers of the system must thus introduce measures to prevent malfunctions or malicious participants from producing false  misleading  or erroneous results  and from using the system as an attack vector  this often involves assigning work randomly to different nodes  presumably with different owners  and checking that at least two different nodes report the same answer for a given work unit  discrepancies would identify malfunctioning and malicious nodes  however  due to the lack of central control over the hardware  there is no way to guarantee that nodes will not drop out of the network at random times  some nodes  like laptops or dialup internet customers  may also be available for computation but not network communications for unpredictable periods  these variations can be accommodated by assigning large work units  thus reducing the need for continuous network connectivity  and reassigning work units when a given node fails to report its results in expected time     the impacts of trust and availability on performance and development difficulty can influence the choice of whether to deploy onto a dedicated cluster  to idle machines internal to the developing organization  or to an open external network of volunteers or contractors  in many cases  the participating nodes must trust the central system not to abuse the access that is being granted  by interfering with the operation of other programs  mangling stored information  transmitting private data  or creating new security holes  other systems employ measures to reduce the amount of trust  client  nodes must place in the central system such as placing applications in virtual machines     public systems or those crossing administrative domains  including different departments in the same organization  often result in the need to run on heterogeneous systems  using different operating systems and hardware architectures  with many languages  there is a trade off between investment in software development and the number of platforms that can be supported  and thus the size of the resulting network   cross platform languages can reduce the need to make this trade off  though potentially at the expense of high performance on any given node  due to run time interpretation or lack of optimization for the particular platform   there are diverse scientific and commercial projects to harness a particular associated grid or for the purpose of setting up new grids  boinc is a common one for various academic projects seeking public volunteers  more are listed at the end of the article     in fact  the middleware can be seen as a layer between the hardware and the software  on top of the middleware  a number of technical areas have to be considered  and these may or may not be middleware independent  example areas include sla management  trust and security  virtual organization management  license management  portals and data management  these technical areas may be taken care of in a commercial solution  though the cutting edge of each area is often found within specific research projects examining the field     for the segmentation of the grid computing market  two perspectives need to be considered  the provider side and the user side     the overall grid market comprises several specific markets  these are the grid middleware market  the market for grid enabled applications  the utility computing market  and the software as a service  saas  market     grid middleware is a specific software product  which enables the sharing of heterogeneous resources  and virtual organizations  it is installed and integrated into the existing infrastructure of the involved company or companies  and provides a special layer placed among the heterogeneous infrastructure and the specific user applications  major grid middlewares are globus toolkit  glite  and unicore     utility computing is referred to as the provision of grid computing and applications as service either as an open grid utility or as a hosting solution for one organization or a vo  major players in the utility computing market are sun microsystems  ibm  and hp     grid enabled applications are specific software applications that can utilize grid infrastructure  this is made possible by the use of grid middleware  as pointed out above     software as a service  saas  is  software that is owned  delivered and managed remotely by one or more providers    gartner       additionally  saas applications are based on a single set of common code and data definitions  they are consumed in a one to many model  and saas uses a pay as you go  payg  model or a subscription model that is based on usage  providers of saas do not necessarily own the computing resources themselves  which are required to run their saas  therefore  saas providers may draw upon the utility computing market  the utility computing market provides computing resources for saas providers     for companies on the demand or user side of the grid computing market  the different segments have significant implications for their it deployment strategy  the it deployment strategy as well as the type of it investments made are relevant aspects for potential grid users and play an important role for grid adoption     cpu scavenging  cycle scavenging  or shared computing creates a  grid  from the unused resources in a network of participants  whether worldwide or internal to an organization   typically this technique uses desktop computer instruction cycles that would otherwise be wasted at night  during lunch  or even in the scattered seconds throughout the day when the computer is waiting for user input or slow devices  in practice  participating computers also donate some supporting amount of disk storage space  ram  and network bandwidth  in addition to raw cpu power citation needed    many volunteer computing projects  such as boinc  use the cpu scavenging model  since nodes are likely to go  offline  from time to time  as their owners use their resources for their primary purpose  this model must be designed to handle such contingencies     the term grid computing originated in the early     s as a metaphor for making computer power as easy to access as an electric power grid  the power grid metaphor for accessible computing quickly became canonical when ian foster and carl kesselman published their seminal work   the grid  blueprint for a new computing infrastructure             cpu scavenging and volunteer computing were popularized beginning in      by distributed net and later in      by seti home to harness the power of networked pcs worldwide  in order to solve cpu intensive research problems citation needed    the ideas of the grid  including those from distributed computing  object oriented programming  and web services  were brought together by ian foster  carl kesselman  and steve tuecke  widely regarded as the  fathers of the grid    they led the effort to create the globus toolkit incorporating not just computation management but also storage management  security provisioning  data movement  monitoring  and a toolkit for developing additional services based on the same infrastructure  including agreement negotiation  notification mechanisms  trigger services  and information aggregation  while the globus toolkit remains the de facto standard for building grid solutions  a number of other tools have been built that answer some subset of services needed to create an enterprise or global grid      in      the term cloud computing came into popularity  which is conceptually similar to the canonical foster definition of grid computing  in terms of computing resources being consumed as electricity is from the power grid   indeed  grid computing is often  but not always  associated with the delivery of cloud computing systems as exemplified by the applogic system from  tera citation needed    grid computing offers a way to solve grand challenge problems such as protein folding  financial modeling  earthquake simulation  and climate weather modeling  grids offer a way of using the information technology resources optimally inside an organization  they also provide a means for offering information technology as a utility for commercial and noncommercial clients  with those clients paying only for what they use  as with electricity or water     grid computing is being applied by the national science foundation s national technology grid  nasa s information power grid  pratt   whitney  bristol myers squibb co   and american express citation needed    one cycle scavenging network is seti home  which was using more than   million computers to achieve       sustained teraflops      lifetime teraflops  as of september     update       as of august      folding home achieves more than   petaflops on over         machines     the european union funded projects through the framework programmes of the european commission  beingrid  business experiments in grid  was a research project funded by the european commission   as an integrated project under the sixth framework programme  fp   sponsorship program  started on june          the project ran    months  until november       the project was coordinated by atos origin  according to the project fact sheet  their mission is  to establish effective routes to foster the adoption of grid computing across the eu and to stimulate research into innovative business models using grid technologies   to extract best practice and common themes from the experimental implementations  two groups of consultants are analyzing a series of pilots  one technical  one business  the project is significant not only for its long duration  but also for its budget  which at      million euros  is the largest of any fp  integrated project  of this       million is provided by the european commission and the remainder by its    contributing partner companies  since the end of the project  the results of beingrid have been taken up and carried forward by it tude com     the enabling grids for e science project  based in the european union and included sites in asia and the united states  was a follow up project to the european datagrid  edg  and evoled into the european grid infrastructure  this  along with the lhc computing grid    lcg   was developed to support experiments using the cern large hadron collider  a list of active sites participating within lcg can be found online   as can real time monitoring of the egee infrastructure    the relevant software and documentation is also publicly accessible    there is speculation that dedicated fiber optic links  such as those installed by cern to address the lcg s data intensive needs  may one day be available to home users thereby providing internet services at speeds up to        times faster than a traditional broadband connection    the european grid infrastructure has been also used for other research activities and experiments such as the simulation of oncological clinical trials       the distributed net project was started in       the nasa advanced supercomputing facility  nas  ran genetic algorithms using the condor cycle scavenger running on about     sun microsystems and sgi workstations     in       united devices operated the united devices cancer research project based on its grid mp product  which cycle scavenges on volunteer pcs connected to the internet  the project ran on about     million machines before its close in            as of       over     million machines running the open source berkeley open infrastructure for network computing  boinc  platform are members of the world community grid  which tops the processing power of the current fastest supercomputer system  china s tianhe i        today there are many definitions of grid computing  