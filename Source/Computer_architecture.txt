 in computer engineering   computer architecture is a set of disciplines that describes the functionality  the organization and the implementation of computer systems  that is  it defines the capabilities of a computer and its programming model in an abstract way  and how the internal organization of the system is designed and implemented to meet the specified capabilities    computer architecture involves many aspects  including instruction set architecture design  microarchitecture design  logic design  and implementation   some fashionable        computer architectures include cluster computing and non uniform memory access     computer architects use computers to design new computers  emulation software can run programs written in a proposed instruction set  while the design is very easy to change at this stage  compiler designers often collaborate with the architects  suggesting improvements in the instruction set  modern emulators may measure time in clock cycles  estimate energy consumption in joules  and give realistic estimates of code size in bytes  these affect the convenience of the user  the power consumption and the size and expense of the computer s largest physical part  its memory  that is  they help to estimate the value of a computer design             the first documented computer architecture was in the correspondence between charles babbage and ada lovelace  describing the analytical engine  two other early and important examples were     the term  architecture  in computer literature can be traced to the work of lyle r  johnson  mohammad usman khan and frederick p  brooks  jr   members in      of the machine organization department in ibm s main research center  johnson had the opportunity to write a proprietary research communication about the stretch  an ibm developed supercomputer for los alamos scientific laboratory  to describe the level of detail for discussing the luxuriously embellished computer  he noted that his description of formats  instruction types  hardware parameters  and speed enhancements were at the level of  system architecture    a term that seemed more useful than  machine organization      subsequently  brooks  a stretch designer  started chapter   of a book  planning a computer system  project stretch  ed  w  buchholz        by writing     computer architecture  like other architecture  is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints     brooks went on to help develop the ibm system      now called the ibm zseries  line of computers  in which  architecture  became a noun defining  what the user needs to know   later  computer users came to use the term in many less explicit ways     the earliest computer architectures were designed on paper and then directly built into the final hardware form   later  computer architecture prototypes were physically built in the form of a transistor transistor logic  ttl  computer such as the prototypes of the      and the pa risc tested  and tweaked  before committing to the final hardware form  as of the     s  new computer architectures are typically  built   tested  and tweaked inside some other computer architecture in a computer architecture simulator  or inside a fpga as a soft microprocessor  or both before committing to the final hardware form     the discipline of computer architecture has three main subcategories      some architects at companies such as intel and amd use finer distinctions     the purpose is to design a computer that maximizes performance while keeping power consumption in check  costs low relative to the amount of expected performance  and is also very reliable  for this  many aspects are to be considered which includes instruction set design  functional organization  logic design  and implementation  the implementation involves integrated circuit design  packaging  power  and cooling  optimization of the design requires familiarity with compilers  operating systems to logic design and packaging     an instruction set architecture  isa  is the interface between the computer s software and hardware and also can be viewed as the programmer s view of the machine  computers do not understand high level languages which have few  if any  language elements that translate directly into a machine s native opcodes  a processor only understands instructions encoded in some numerical fashion  usually as binary numbers  software tools  such as compilers  translate high level languages  such as c into instructions     besides instructions  the isa defines items in the computer that are available to a program e g  data types  registers  addressing modes  and memory  instructions locate operands with register indexes  or names  and memory addressing modes     the isa of a computer is usually described in a small book or pamphlet  which describes how the instructions are encoded  also  it may define short  vaguely  mnenonic names for the instructions  the names can be recognized by a software development tool called an assembler  an assembler is a computer program that translates a human readable form of the isa into a computer readable form  disassemblers are also widely available  usually in debuggers  software programs to isolate and correct malfunctions in binary computer programs     isas vary in quality and completeness  a good isa compromises between programmer convenience  more operations can be better   cost of the computer to interpret the instructions  cheaper is better   speed of the computer  faster is better   and size of the code  smaller is better   for example  a single instruction isa is possible  inexpensive  and fast   e g   subtract and jump if zero  it was actually used in the ssem   but it was not convenient or helpful to make programs small  memory organization defines how instructions interact with the memory  and also how different parts of memory interact with each other     computer organization helps optimize performance based products  for example  software engineers need to know the processing ability of processors  they may need to optimize software in order to gain the most performance at the least expense  this can require quite detailed analysis of the computer organization  for example  in a multimedia decoder  the designers might need to arrange for most data to be processed in the fastest data path and the various components are assumed to be in place and task is to investigate the organisational structure to verify the computer parts operates     computer organization also helps plan the selection of a processor for a particular project  multimedia projects may need very rapid data access  while supervisory software may need fast interrupts  sometimes certain tasks need additional components as well  for example  a computer capable of virtualization needs virtual memory hardware so that the memory of different simulated computers can be kept separated  computer organization and features also affect power consumption and processor cost     once an instruction set and micro architecture are described  a practical machine must be designed  this design process is called the implementation  implementation is usually not considered architectural definition  but rather hardware design engineering  implementation can be further broken down into several  not fully distinct  steps     for cpus  the entire implementation process is often called cpu design     the exact form of a computer system depends on the constraints and goals  computer architectures usually trade off standards  power versus performance  cost  memory capacity  latency  latency is the amount of time that it takes for information from one node to travel to the source  and throughput  sometimes other considerations  such as features  size  weight  reliability  and expandability are also factors     the most common scheme does an in depth power analysis and figures out how to keep power consumption low  while maintaining adequate performance     modern computer performance is often described in mips per mhz  millions of instructions per millions of cycles of clock speed   this measures the efficiency of the architecture at any clock speed  since a faster clock can make a faster computer  this is a useful  widely applicable measurement  historic computers had mips mhz as low as      see instructions per second   simple modern processors easily reach near    superscalar processors may reach three to five by executing several instructions per clock cycle  multicore and vector processing cpus can multiply this further by acting on a lot of data per instruction  which have several cpus executing in parallel     counting machine language instructions would be misleading because they can do varying amounts of work in different isas  the  instruction  in the standard measurements is not a count of the isa s actual machine language instructions  but a historical unit of measurement  usually based on the speed of the vax computer architecture     historically  many people measured a computer s speed by the clock rate  usually in mhz or ghz   this refers to the cycles per second of the main clock of the cpu  however  this metric is somewhat misleading  as a machine with a higher clock rate may not necessarily have higher performance  as a result manufacturers have moved away from clock speed as a measure of performance     other factors influence speed  such as the mix of functional units  bus speeds  available memory  and the type and order of instructions in the programs being run     in a typical home computer  the simplest  most reliable way to speed performance is usually to add random access memory  ram   more ram increases the likelihood that needed data or a program is in ram so the system is less likely to need to move memory data from the disk  the disk is often ten thousand times slower than ram because it has mechanical parts that must move to access its data     there are two main types of speed  latency and throughput  latency is the time between the start of a process and its completion  throughput is the amount of work done per unit time  interrupt latency is the guaranteed maximum response time of the system to an electronic event  e g  when the disk drive finishes moving some data      performance is affected by a very wide range of design choices   for example  pipelining a processor usually makes latency worse  slower  but makes throughput better  computers that control machinery usually need low interrupt latencies  these computers operate in a real time environment and fail if an operation is not completed in a specified amount of time  for example  computer controlled anti lock brakes must begin braking within a predictable  short time after the brake pedal is sensed     the performance of a computer can be measured using other metrics  depending upon its application domain  a system may be cpu bound  as in numerical calculation   i o bound  as in a webserving application  or memory bound  as in video editing   power consumption has become important in servers and portable devices like laptops     benchmarking tries to take all these factors into account by measuring the time a computer takes to run through a series of test programs  although benchmarking shows strengths  it may not help one to choose a computer  often the measured machines split on different measures  for example  one system might handle scientific applications quickly  while another might play popular video games more smoothly  furthermore  designers may add special features to their products  in hardware or software  that permit a specific benchmark to execute quickly but don t offer similar advantages to general tasks     power consumption is another measurement that is important in modern computers  power efficiency can often be traded for speed or lower cost  the typical measurement in this case is mips w  millions of instructions per second per watt      modern circuits have less power per transistor as the number of transistors per chip grows  therefore  power efficiency has increased in importance  recent processor designs such as intel s haswell  microarchitecture   put more emphasis on increasing power efficiency  also  in the world of embedded computing  power efficiency has long been and remains an important goal next to throughput and latency  