 reconfigurable computing is a computer architecture combining some of the flexibility of software with the high performance of hardware by processing with very flexible high speed computing fabrics like field programmable gate arrays  fpgas   the principal difference when compared to using ordinary microprocessors is the ability to make substantial changes to the datapath itself in addition to the control flow  on the other hand  the main difference with custom hardware  i e  application specific integrated circuits  asics  is the possibility to adapt the hardware during runtime by  loading  a new circuit on the reconfigurable fabric             the concept of reconfigurable computing has existed since the     s  when gerald estrin s landmark paper proposed the concept of a computer made of a standard processor and an array of  reconfigurable  hardware    the main processor would control the behavior of the reconfigurable hardware  the latter would then be tailored to perform a specific task  such as image processing or pattern matching  as quickly as a dedicated piece of hardware  once the task was done  the hardware could be adjusted to do some other task  this resulted in a hybrid computer structure combining the flexibility of software with the speed of hardware  unfortunately this idea was far ahead of its time in needed electronic technology     in the     s and     s there was a renaissance in this area of research with many proposed reconfigurable architectures developed in industry and academia   such as  copacobana  matrix  garp   elixent  pact xpp  silicon hive  montium  pleiades  morphosys  picoga   such designs were feasible due to the constant progress of silicon technology that let complex designs be implemented on one chip  the world s first commercial reconfigurable computer  the algotronix chs x   was completed in       it was not a commercial success  but was promising enough that xilinx  the inventor of the field programmable gate array  fpga  bought the technology and hired the algotronix staff      the fundamental model of the reconfigurable computing machine paradigm  the data stream based anti machine is well illustrated by the differences to other machine paradigms that were introduced earlier  as shown by nick tredennick s following classification scheme of computing paradigms  see  table    nick tredennick s paradigm classification scheme         computer scientist reiner hartenstein describes reconfigurable computing in terms of an anti machine that  according to him  represents a fundamental paradigm shift away from the more conventional von neumann machine    hartenstein calls it reconfigurable computing paradox  that software to configware migration  software to fpga migration  results in reported speed up factors of up to more than four orders of magnitude  as well as a reduction in electricity consumption by up to almost four orders of magnitude although the technological parameters of fpgas are behind the gordon moore curve by about four orders of magnitude  and the clock frequency is substantially lower than that of microprocessors  this paradox is due to a paradigm shift  and is also partly explained by the von neumann syndrome  von neumann bottleneck      high performance reconfigurable computing  hprc  is a computer architecture combining reconfigurable computing based accelerators like fpgas with cpus or multi core microprocessors     the increase of logic in an fpga has enabled larger and more complex algorithms to be programmed into the fpga  the attachment of such an fpga to a modern cpu over a high speed bus  like pci express  has enabled the configurable logic to act more like a coprocessor rather than a peripheral  this has brought reconfigurable computing into the high performance computing sphere     furthermore by replicating an algorithm on an fpga or the use of a multiplicity of fpgas has enabled reconfigurable simd systems to be produced where several computational devices can concurrently operate on different data  which is highly parallel computing     this heterogeneous systems technique is used in computing research and especially in supercomputing   a      paper reported speed up factors of more than   orders of magnitude and energy saving factors by up to almost   orders of magnitude    some supercomputer firms offer heterogeneous processing blocks including fpgas as accelerators citation needed one research area is the twin paradigm programming tool flow productivity obtained for such heterogeneous systems       the us national science foundation has a center for high performance reconfigurable computing  chrec     in april      the fourth many core and reconfigurable supercomputing conference was held in europe       commercial high performance reconfigurable computing systems are beginning to emerge with the announcement of ibm integrating fpgas with its power processor       partial re configuration is the process of changing a portion of reconfigurable hardware circuitry while the other part is still running operating  field programmable gate arrays are often used as a support to partial reconfiguration     electronic hardware  like software  can be designed modularly  by creating subcomponents and then higher level components to instantiate them  in many cases it is useful to be able to swap out one or several of these subcomponents while the fpga is still operating     normally  reconfiguring an fpga requires it to be held in reset while an external controller reloads a design onto it  partial reconfiguration allows for critical parts of the design to continue operating while a controller either on the fpga or off of it loads a partial design into a reconfigurable module  partial reconfiguration also can be used to save space for multiple designs by only storing the partial designs that change between designs     a common example for when partial reconfiguration would be useful is the case of a communication device  if the device is controlling multiple connections  some of which require encryption  it would be useful to be able to load different encryption cores without bringing the whole controller down     partial reconfiguration is not supported on all fpgas  a special software flow with emphasis on modular design is required  typically the design modules are built along well defined boundaries inside the fpga that require the design to be specially mapped to the internal hardware     from the functionality of the design  partial reconfiguration can be divided into two groups       there are two styles of partial reconfiguration of fpga devices from xilinx  module based and difference based     with the advent of affordable fpga boards  there is an ever increasing number of students  and hobbyists  projects that seek to recreate vintage computers or implement more novel architectures               such projects are built with reconfigurable hardware  fpgas   and some devices support emulation of multiple vintage computers using a single reconfigurable hardware  c one      mitrionics has developed a sdk that enables software written using a single assignment language to be compiled and executed on fpga based computers  the mitrion c software language and mitrion processor enable software developers to write and execute applications on fpga based computers in the same manner as with other computing technologies  such as graphical processing units   gpus    cell based processors  parallel processing units   ppus    multi core cpus  and traditional single core cpu clusters   out of business     national instruments have developed a hybrid embedded computing system called compactrio  compactrio systems consist of reconfigurable chassis housing the user programmable fpga  hot swappable i o modules  real time controller for deterministic communication and processing  and graphical labview software for rapid rt and fpga programming     a fully fpga based computer addressing several markets is the copacobana  the cost optimized codebreaker and analyzer and its successor rivyera  a spin off company sciengines gmbh   of the copacobana project of the universities of bochum and kiel in germany currently sells the fourth generation of fully fpga based computers  well published configurations utilize for example     fpgas per single computer making copacobana and rivyera a well known reference platform for cryptanalysis and bioinformatics     as an emerging field  classifications of reconfigurable architectures are still being developed and refined as new architectures are developed  no unifying taxonomy has been suggested to date  however  several recurring parameters can be used to classify these systems     the granularity of the reconfigurable logic is defined as the size of the smallest functional unit  configurable logic block  clb  that is addressed by the mapping tools  high granularity  which can also be known as fine grained  often implies a greater flexibility when implementing algorithms into the hardware  however  there is a penalty associated with this in terms of increased power  area and delay due to greater quantity of routing required per computation  fine grained architectures work at the bit level manipulation level  whilst coarse grained processing elements  reconfigurable datapath unit  rdpu  are better optimised for standard data path applications  one of the drawbacks of coarse grained architectures are that they tend to lose some of their utilisation and performance if they need to perform smaller computations than their granularity provides  for example for a one bit add on a four bit wide functional unit would waste three bits  this problem can be solved by having a coarse grain array  reconfigurable datapath array  rdpa  and a fpga on the same chip     coarse grained architectures  rdpa  are intended for the implementation for algorithms needing word width data paths  rdpu   as their functional blocks are optimized for large computations and typically comprise word wide arithmetic logic units  alu   they will perform these computations more quickly and with more power efficiency than a set of interconnected smaller functional units  this is due to the connecting wires being shorter  resulting in less wire capacitance and hence faster and lower power designs  a potential undesirable consequence of having larger computational blocks is that when the size of operands may not match the algorithm an inefficient utilisation of resources can result  often the type of applications to be run are known in advance allowing the logic  memory and routing resources to be tailored to enhance the performance of the device whilst still providing a certain level of flexibility for future adaptation  examples of this are domain specific arrays aimed at gaining better performance in terms of power  area  throughput than their more generic finer grained fpga cousins by reducing their flexibility     configuration of these reconfigurable systems can happen at deployment time  between execution phases or during execution  in a typical reconfigurable system  a bit stream is used to program the device at deployment time  fine grained systems by their own nature require greater configuration time than more coarse grained architectures due to more elements needing to be addressed and programmed  therefore more coarse grained architectures gain from potential lower energy requirements  as less information is transferred and utilised  intuitively  the slower the rate of reconfiguration the smaller the energy consumption as the associated energy cost of reconfiguration are amortised over a longer period of time  partial re configuration aims to allow part of the device to be reprogrammed while another part is still performing active computation  partial re configuration allows smaller reconfigurable bit streams thus not wasting energy on transmitting redundant information in the bit stream  compression of the bit stream is possible but careful analysis is to be carried out to ensure that the energy saved by using smaller bit streams is not outweighed by the computation needed to decompress the data     often the reconfigurable array is used as a processing accelerator attached to a host processor  the level of coupling determines the type of data transfers  latency  power  throughput and overheads involved when utilising the reconfigurable logic  some of the most intuitive designs use a peripheral bus to provide a coprocessor like arrangement for the reconfigurable array  however  there have also been implementations where the reconfigurable fabric is much closer to the processor  some are even implemented into the data path  utilising the processor registers  the job of the host processor is to perform the control functions  configure the logic  schedule data and to provide external interfacing     the flexibility in reconfigurable devices mainly comes from their routing interconnect  one style of interconnect made popular by fpgas vendors  xilinx and altera are the island style layout  where blocks are arranged in an array with vertical and horizontal routing  a layout with inadequate routing may suffer from poor flexibility and resource utilisation  therefore providing limited performance  if too much interconnect is provided this requires more transistors than necessary and thus more silicon area  longer wires and more power consumption  