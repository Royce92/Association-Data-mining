 in computing  load balancing distributes workloads across multiple computing resources  such as computers  a computer cluster  network links  central processing units or disk drives  load balancing aims to optimize resource use  maximize throughput  minimize response time  and avoid overload of any single resource  using multiple components with load balancing instead of a single component may increase reliability through redundancy  load balancing usually involves dedicated software or hardware  such as a multilayer switch or a domain name system server process     load balancing differs from channel bonding in that load balancing divides traffic between network interfaces on a network socket  osi model layer    basis  while channel bonding implies a division of traffic between physical interfaces at a lower level  either per packet  osi model layer    or on a data link  osi model layer    basis             one of the most commonly used applications of load balancing is to provide a single internet service from multiple servers  sometimes known as a server farm  commonly load balanced systems include popular web sites  large internet relay chat networks  high bandwidth file transfer protocol sites  network news transfer protocol  nntp  servers  domain name system  dns  servers  and databases     for internet services  the load balancer is usually a software program that is listening on the port where external clients connect to access services  the load balancer forwards requests to one of the  backend  servers  which usually replies to the load balancer  this allows the load balancer to reply to the client without the client ever knowing about the internal separation of functions  it also prevents clients from contacting back end servers directly  which may have security benefits by hiding the structure of the internal network and preventing attacks on the kernel s network stack or unrelated services running on other ports     some load balancers provide a mechanism for doing something special in the event that all backend servers are unavailable  this might include forwarding to a backup load balancer  or displaying a message regarding the outage  load balancing gives the it team a chance to achieve a significantly higher fault tolerance  it can automatically provide the amount of capacity needed to respond to any increase or decrease of application traffic     it is also important that the load balancer itself does not become a single point of failure  usually load balancers are implemented in high availability pairs which may also replicate session persistence data if required by the specific application      an alternate method of load balancing  which does not necessarily require a dedicated software or hardware node  is called round robin dns  in this technique  multiple ip addresses are associated with a single domain name  clients are expected to choose which server to connect to  unlike the use of a dedicated load balancer  this technique exposes to clients the existence of multiple backend servers  the technique has other advantages and disadvantages  depending on the degree of control over the dns server and the granularity of load balancing desired     another more effective technique for load balancing using dns is to delegate www example org as a sub domain whose zone is served by each of the same servers that are serving the web site  this technique works particularly well where individual servers are spread geographically on the internet  for example     however  the zone file for www example org on each server is different such that each server resolves its own ip address as the a record   on server one the zone file for www example org reports     on server two the same zone file contains     this way  when a server is down  its dns will not respond and the web service does not receive any traffic  if the line to one server is congested  the unreliability of dns ensures less http traffic reaches that server  furthermore  the quickest dns response to the resolver is nearly always the one from the network s closest server  ensuring geo sensitive load balancingcitation needed  a short ttl on the a record helps to ensure traffic is quickly diverted when a server goes down  consideration must be given the possibility that this technique may cause individual clients to switch between individual servers in mid session     numerous scheduling algorithms are used by load balancers to determine which back end server to send a request to  simple algorithms include random choice or round robin  more sophisticated load balancers may take additional factors into account  such as a server s reported load  least response times  up down status  determined by a monitoring poll of some kind   number of active connections  geographic location  capabilities  or how much traffic it has recently been assigned     an important issue when operating a load balanced service is how to handle information that must be kept across the multiple requests in a user s session  if this information is stored locally on one backend server  then subsequent requests going to different backend servers would not be able to find it  this might be cached information that can be recomputed  in which case load balancing a request to a different backend server just introduces a performance issue     ideally the cluster of servers behind the load balancer should be session aware  so that if a client connects to any backend server at any time the user experience is unaffected  this is usually achieved with a shared database or an in memory session database  for example memcached     one basic solution to the session data issue is to send all requests in a user session consistently to the same backend server  this is known as persistence or stickiness  a significant downside to this technique is its lack of automatic failover  if a backend server goes down  its per session information becomes inaccessible  and any sessions depending on it are lost  the same problem is usually relevant to central database servers  even if web servers are  stateless  and not  sticky   the central database is  see below      assignment to a particular server might be based on a username  client ip address  or be random  because of changes of the client s perceived address resulting from dhcp  network address translation  and web proxies this method may be unreliable  random assignments must be remembered by the load balancer  which creates a burden on storage  if the load balancer is replaced or fails  this information may be lost  and assignments may need to be deleted after a timeout period or during periods of high load to avoid exceeding the space available for the assignment table  the random assignment method also requires that clients maintain some state  which can be a problem  for example when a web browser has disabled storage of cookies  sophisticated load balancers use multiple persistence techniques to avoid some of the shortcomings of any one method     another solution is to keep the per session data in a database  generally this is bad for performance because it increases the load on the database  the database is best used to store information less transient than per session data  to prevent a database from becoming a single point of failure  and to improve scalability  the database is often replicated across multiple machines  and load balancing is used to spread the query load across those replicas  microsoft s asp net state server technology is an example of a session database  all servers in a web farm store their session data on state server and any server in the farm can retrieve the data     efficient but simple approaches are a very common case where the client is a web browser  per session data can be stored in the browser itself  one way to achieve this is to use a browser cookie  suitably time stamped and encrypted  another is url rewriting  storing session data on the client is generally the preferred solution  then the load balancer is free to pick any backend server to handle a request  however  this method of state data handling is poorly suited to some complex business logic scenarios  where session state payload is big and recomputing it with every request on a server is not feasible  url rewriting has major security issues  because the end user can easily alter the submitted url and thus change session streams     hardware and software load balancers may have a variety of special features  the fundamental feature of a load balancer is to be able to distribute incoming requests over a number of backend servers in the cluster according to a scheduling algorithm  most of the following features are vendor specific     load balancing can be useful in applications with redundant communications links  for example  a company may have multiple internet connections ensuring network access if one of the connections fails  a failover arrangement would mean that one link is designated for normal use  while the second link is used only if the primary link fails     using load balancing  both links can be in use all the time  a device or program monitors the availability of all links and selects the path for sending packets  the use of multiple links simultaneously increases the available bandwidth     the ieee approved the ieee      aq standard may        also known and documented in most books as shortest path bridging  spb   spb allows all links to be active through multiple equal cost paths  provides faster convergence times to reduce down time  and simplifies the use of load balancing in mesh network topologies  partially connected and or fully connected  by allowing traffic to load share across all paths of a network    spb is designed to virtually eliminate human error during configuration and preserves the plug and play nature that established ethernet as the de facto protocol at layer        many telecommunications companies have multiple routes through their networks or to external networks  they use sophisticated load balancing to shift traffic from one path to another to avoid network congestion on any particular link  and sometimes to minimize the cost of transit across external networks or improve network reliability     another way of using load balancing is in network monitoring activities  load balancers can be used to split huge data flows into several sub flows and use several network analyzers  each reading a part of the original data  this is very useful for monitoring fast networks like   gbe or stm    where complex processing of the data may not be possible at wire speed     load balancing is often used to implement failover the continuation of a service after the failure of one or more of its components  the components are monitored continually  e g   web servers may be monitored by fetching known pages   and when one becomes non responsive  the load balancer is informed and no longer sends traffic to it  when a component comes back on line  the load balancer begins to route traffic to it again  for this to work  there must be at least one component in excess of the service s capacity  this can be much less expensive and more flexible than failover approaches where each single live component is paired with a single backup component that takes over in the event of a failure  some types of raid systems can also utilize hot spare for a similar effect  