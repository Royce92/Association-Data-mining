 in computer networks  a proxy server is a server  a computer system or an application  that acts as an intermediary for requests from clients seeking resources from other servers  a client connects to the proxy server  requesting some service  such as a file  connection  web page  or other resource available from a different server and the proxy server evaluates the request as a way to simplify and control its complexity  proxies were invented to add structure and encapsulation to distributed systems   today  most proxies are web proxies  facilitating access to content on the world wide web and providing anonymity             a proxy server may reside on the user s local computer  or at various points between the user s computer and destination servers on the internet     an open proxy is a forwarding proxy server that is accessible by any internet user  gordon lyon estimates there are  hundreds of thousands  of open proxies on the internet   an anonymous open proxy allows users to conceal their ip address while browsing the web or using other internet services  there are varying degrees of anonymity however  as well as a number of methods of  tricking  the client into revealing itself regardless of the proxy being used     a reverse proxy  or surrogate  is a proxy server that appears to clients to be an ordinary server  requests are forwarded to one or more proxy servers which handle the request  the response from the proxy server is returned as if it came directly from the origin server  leaving the client no knowledge of the origin servers   reverse proxies are installed in the neighborhood of one or more web servers  all traffic coming from the internet and with a destination of one of the neighborhood s web servers goes through the proxy server  the use of  reverse  originates in its counterpart  forward proxy  since the reverse proxy sits closer to the web server and serves only a restricted set of websites  there are several reasons for installing reverse proxy servers     a content filtering web proxy server provides administrative control over the content that may be relayed in one or both directions through the proxy  it is commonly used in both commercial and non commercial organizations  especially schools  to ensure that internet usage conforms to acceptable use policy     a content filtering proxy will often support user authentication  to control web access  it also usually produces logs  either to give detailed information about the urls accessed by specific users  or to monitor bandwidth usage statistics  it may also communicate to daemon based and or icap based antivirus software to provide security against virus and other malware by scanning incoming content in real time before it enters the network     many work places  schools and colleges restrict the web sites and online services that are made available in their buildings  governments also censor undesirable content  this is done either with a specialized proxy  called a content filter  both commercial and free products are available   or by using a cache extension protocol such as icap  that allows plug in extensions to an open caching architecture     requests may be filtered by several methods  such as a url or dns blacklists blacklist  url regex filtering  mime filtering  or content keyword filtering  some products have been known to employ content analysis techniques to look for traits commonly used by certain types of content providers citation needed blacklists are often provided and maintained by web filtering companies  often grouped into categories  pornography  gambling  shopping  social networks  etc       assuming the requested url is acceptable  the content is then fetched by the proxy  at this point a dynamic filter may be applied on the return path  for example  jpeg files could be blocked based on fleshtone matches  or language filters could dynamically detect unwanted language  if the content is rejected then an http fetch error may be returned to the requester     most web filtering companies use an internet wide crawling robot that assesses the likelihood that a content is a certain type  the resultant database is then corrected by manual labor based on complaints or known flaws in the content matching algorithms     some proxies scan outbound content  e g   for data loss prevention  or scan content for malicious software     web filtering proxies are not able to peer inside secure sockets http transactions  assuming the chain of trust of ssl tls has not been tampered with     the ssl tls chain of trust relies on trusted root certificate authorities  in a workplace setting where the client is managed by the organization  trust might be granted to a root certificate whose private key is known to the proxy  consequently  a root certificate generated by the proxy is installed into the browser ca list by it staff     in such situations  proxy analysis of the contents of a ssl tls transaction becomes possible  the proxy is effectively operating a man in the middle attack  allowed by the client s trust of a root certificate the proxy owns     if the destination server filters content based on the origin of the request  the use of a proxy can circumvent this filter  for example  a server using ip based geolocation to restrict its service to a certain country can be accessed using a proxy located in that country to access the service     web proxies are the most common means of bypassing government censorship  although no more than    of internet users use any circumvention tools      in some cases users can circumvent proxies which filter using blacklists using services designed to proxy information from a non blacklisted location      proxies can be installed in order to eavesdrop upon the data flow between client machines and the web  all content sent or accessedxa   including passwords submitted and cookies usedxa   can be captured and analyzed by the proxy operator  for this reason  passwords to online services  such as webmail and banking  should always be exchanged over a cryptographically secured connection  such as ssl  by chaining proxies which do not reveal data about the original requester  it is possible to obfuscate activities from the eyes of the user s destination  however  more traces will be left on the intermediate hops  which could be used or offered up to trace the user s activities  if the policies and administrators of these other proxies are unknown  the user may fall victim to a false sense of security just because those details are out of sight and mind  in what is more of an inconvenience than a risk  proxy users may find themselves being blocked from certain web sites  as numerous forums and web sites block ip addresses from proxies known to have spammed or trolled the site  proxy bouncing can be used to maintain your privacy     a caching proxy server accelerates service requests by retrieving content saved from a previous request made by the same client or even other clients  caching proxies keep local copies of frequently requested resources  allowing large organizations to significantly reduce their upstream bandwidth usage and costs  while significantly increasing performance  most isps and large businesses have a caching proxy  caching proxies were the first kind of proxy server  web proxies are commonly used to cache web pages from a web server   poorly implemented caching proxies can cause problems  such as an inability to use user authentication      a proxy that is designed to mitigate specific link related issues or degradations is a performance enhancing proxy  peps   these typically are used to improve tcp performance in the presence of high round trip times or high packet loss  such as wireless or mobile phone networks   or highly asymmetric links featuring very different upload and download rates  peps can make more efficient use of the network  for example by merging tcp acks or compressing data sent at the application layer     another important use of the proxy server is to reduce the hardware cost  an organization may have many systems on the same network or under control of a single server  prohibiting the possibility of an individual connection to the internet for each system  in such a case  the individual systems can be connected to one proxy server  and the proxy server connected to the main server     a translation proxy is a proxy server that is used to localize a website experience for different markets  traffic from global audiences is routed through the translation proxy to the source website  as visitors browse the proxied site  requests go back to the source site where pages are rendered  original language content in the response is replaced by translated content as it passes back through the proxy  the translations used in a translation proxy can be either machine translation  human translation  or a combination of machine and human translation  different translation proxy implementations have different capabilities  some allow further customization of the source site for local audiences such as excluding source content or substituting source content with original local content     an anonymous proxy server  sometimes called a web proxy  generally attempts to anonymize web surfing  there are different varieties of anonymizers  the destination server  the server that ultimately satisfies the web request  receives requests from the anonymizing proxy server  and thus does not receive information about the end user s address  the requests are not anonymous to the anonymizing proxy server  however  and so a degree of trust is present between the proxy server and the user  many proxy servers are funded through a continued advertising link to the user     access control  some proxy servers implement a logon requirement  in large organizations  authorized users must log on to gain access to the web  the organization can thereby track usage to individuals  some anonymizing proxy servers may forward data packets with header lines such as http_via  http_x_forwarded_for  or http_forwarded  which may reveal the ip address of the client  other anonymizing proxy servers  known as elite or high anonymity proxies  only include the remote_addr header with the ip address of the proxy server  making it appear that the proxy server is the client  a website could still suspect a proxy is being used if the client sends packets which include a cookie from a previous visit that did not use the high anonymity proxy server  clearing cookies  and possibly the cache  would solve this problem     advertisers use proxy servers for validating  checking and quality assurance of geotargeted ads  a geotargeting ad server checks the request source ip address and uses a geo ip database to determine the geographic source of requests   using a proxy server that is physically located inside a specific country or a city gives advertisers the ability to test geotargeted ads       a proxy can keep the internal network structure of a company secret by using network address translation  which can help the security of the internal network    this makes requests from machines and users on the local network anonymous  proxies can also be combined with firewalls     an incorrectly configured proxy can provide access to a network otherwise isolated from the internet      proxies allow web sites to make web requests to externally hosted resources  e g  images  music files  etc   when cross domain restrictions prohibit the web site from linking directly to the outside domains  proxies also allow the browser to make web requests to externally hosted content on behalf of a website when cross domain restrictions  in place to protect websites from the likes of data theft  prohibit the browser from directly accessing the outside domains     web proxies forward http requests  some web proxies allow the http connect to set up forwarding of arbitrary data through the connection  normally this is only allowed to port     to allow forwarding of https traffic     examples of web proxy servers include apache  with mod_proxy or traffic server   haproxy  iis configured as proxy  e g   with application request routing   nginx  privoxy  squid  varnish  reverse proxy only   wingate  ziproxy  tinyproxy  rabbit  and polipo     socks also forwards arbitrary data after a connection phase  and is similar to http connect in web proxies     also known as an intercepting proxy  inline proxy  or forced proxy  a transparent proxy intercepts normal communication at the network layer without requiring any special client configuration  clients need not be aware of the existence of the proxy  a transparent proxy is normally located between the client and the internet  with the proxy performing some of the functions of a gateway or router       rfc       hypertext transfer protocol http      offers standard definitions     tcp intercept is a traffic filtering security feature that protects tcp servers from tcp syn flood attacks  which are a type of denial of service attack  tcp intercept is available for ip traffic only     in      a security flaw in the way that transparent proxies operate was published by robert auger    and the computer emergency response team issued an advisory listing dozens of affected transparent and intercepting proxy servers       intercepting proxies are commonly used in businesses to enforce acceptable use policy  and to ease administrative overheads  since no client browser configuration is required  this second reason however is mitigated by features such as active directory group policy  or dhcp and automatic proxy detection     intercepting proxies are also commonly used by isps in some countries to save upstream bandwidth and improve customer response times by caching  this is more common in countries where bandwidth is more limited  e g  island nations  or must be paid for     the diversion   interception of a tcp connection creates several issues  firstly the original destination ip and port must somehow be communicated to the proxy  this is not always possible  e g   where the gateway and proxy reside on different hosts   there is a class of cross site attacks that depend on certain behaviour of intercepting proxies that do not check or have access to information about the original  intercepted  destination  this problem may be resolved by using an integrated packet level and application level appliance or software which is then able to communicate this information between the packet handler and the proxy     intercepting also creates problems for http authentication  especially connection oriented authentication such as ntlm  since the client browser believes it is talking to a server rather than a proxy  this can cause problems where an intercepting proxy requires authentication  then the user connects to a site which also requires authentication     finally intercepting connections can cause problems for http caches  since some requests and responses become uncacheable by a shared cache     in integrated firewall   proxy servers where the router firewall is on the same host as the proxy  communicating original destination information can be done by any method  for example microsoft tmg or wingate     interception can also be performed using cisco s wccp  web cache control protocol   this proprietary protocol resides on the router and is configured from the cache  allowing the cache to determine what ports and traffic is sent to it via transparent redirection from the router  this redirection can occur in one of two ways  gre tunneling  osi layer    or mac rewrites  osi layer        once traffic reaches the proxy machine itself interception is commonly performed with nat  network address translation   such setups are invisible to the client browser  but leave the proxy visible to the web server and other devices on the internet side of the proxy  recent linux and some bsd releases provide tproxy  transparent proxy  which performs ip level  osi layer    transparent interception and spoofing of outbound traffic  hiding the proxy ip address from other network devices     there are several methods that can often be used to detect the presence of an intercepting proxy server     a cgi web proxy accepts target urls using a web form in the user s browser window  processes the request  and returns the results to the user s browser  consequently it can be used on a device or network that does not allow  true  proxy settings to be changed  the first recorded cgi proxy was developed by american computer scientist richard windmann        some cgi proxies were set up for purposes such as making websites more accessible to disabled people  but have since been shut down due to excessive traffic  usually caused by a third party advertising the service as a means to bypass local filtering  since many of these users don t care about the collateral damage they are causing  it became necessary for organizations to hide their proxies  disclosing the urls only to those who take the trouble to contact the organization and demonstrate a genuine need citation needed    users wanting to bypass web filtering  that want to prevent anyone from monitoring what they are doing  will typically search the internet for an open and anonymous https transparent proxy  they will then program their browser to proxy all requests through the web filter to this anonymous proxy  those requests will be encrypted with https  the web filter cannot distinguish these transactions from  say  a legitimate access to a financial website  thus  content filters are only effective against unsophisticated users     use of https proxies are detectable even without examining the encrypted data  based simply on firewall monitoring of addresses for frequency of use and bandwidth usage  if a massive amount of data is being directed through an address that is within an isp address range such as comcast  it is likely a home operated proxy server  either the single address or the entire isp address range is then blocked at the firewall to prevent further connections     a suffix proxy allows a user to access web content by appending the name of the proxy server to the url of the requested content  e g   en wikipedia org suffixproxy com    suffix proxy servers are easier to use than regular proxy servers but they do not offer high levels of anonymity and their primary use is for bypassing web filters  however  this is rarely used due to more advanced web filters     tor  short for the onion router  is a system intended to enable online anonymity    tor client software routes internet traffic through a worldwide volunteer network of servers in order to conceal a user s location or usage from someone conducting network surveillance or traffic analysis  using tor makes it more difficult to trace internet activity  including  visits to web sites  online posts  instant messages and other communication forms   back to the user    it is intended to protect users  personal freedom  privacy  and ability to conduct confidential business by keeping their internet activities from being monitored      onion routing  refers to the layered nature of the encryption service  the original data are encrypted and re encrypted multiple times  then sent through successive tor relays  each one of which decrypts a  layer  of encryption before passing the data on to the next relay and ultimately the destination  this reduces the possibility of the original data being unscrambled or understood in transit       the tor client is free software  and there are no additional charges to use the network     the i p anonymous network   i p   is a proxy network aiming at online anonymity  it implements garlic routing  which is an enhancement of tor s onion routing  i p is fully distributed and works by encrypting all communications in various layers and relaying them through a network of routers run by volunteers in various locations  by keeping the source of the information hidden  i p offers censorship resistance  the goals of i p are to protect users  personal freedom  privacy  and ability to conduct confidential business     each user of i p runs an i p router on their computer  node   the i p router takes care of finding other peers and building anonymizing tunnels through them  i p provides proxies for all protocols  http  irc  socks           the software is free and open source  and the network is free of charge to use     most of the time  proxy  refers to a layer   application on the osi reference model  however  another way of proxying is through layer   and is known as network address translation  nat   the difference between these two proxy technologies is the layer in which they operate  and the procedure to configuring the proxy clients and proxy servers     in client configuration of layer   proxy  nat   configuring the gateway is sufficient  however  for client configuration of a layer   proxy  the destination of the packets that the client generates must always be the proxy server  layer     then the proxy server reads each packet and finds out the true destination     because nat operates at layer    it is less resource intensive than the layer   proxy  but also less flexible  as we compare these two technologies  we might encounter a terminology known as  transparent firewall   transparent firewall means that the layer   proxy uses the layer   proxy advantages without the knowledge of the client  the client presumes that the gateway is a nat in layer    and it does not have any idea about the inside of the packet  but through this method the layer   packets are sent to the layer   proxy for investigation     a dns proxy server takes dns queries from a  usually local  network and forwards them to an internet domain name server  it may also cache dns records     there are client programs that  socks ify     which allows adaptation of any networked software to connect to external networks via certain types of proxy servers  mostly socks   